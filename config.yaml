# General parameters for training and prediction:
dataset_table: "yeast_metadata.csv"   # Path to metadata csv file
output_dir: "out"                     # Output directory
work_dir: "work"                      # Destination directory of intermediate files
model_path: "model.pkl"               # Output model using .pkl extension

# When running in the cluster:
cluster:
  logdir: "logs"

# Tomogram sets used for training or prediction
tomos_sets:
  training_list: ["190301/001", "190301/002"] # Tomograms in dataset_table for training ["tomo1", "tomo2", ...]
  prediction_list: ["190301/006"]             # Tomograms in dataset_table for prediction ["tomo1", "tomo2", ...]

cross_validation:
  active: false
  folds: 2
  statistics_file: "cv_statistics.csv"

training:
  active: false
  semantic_classes: ['ribo']             # List of k classes that the network will learn, separated by commas
  processing_tomo: "tomo"                # Column name in dataset_table corresponding to raw tomo used for training
  box_size: 64                          # Box side of the partition
  min_label_fraction: 0.001              # Minimum label required in each box considered for the training partition
  overlap: 12                            # Thickness of overlap for training partition
  batch_size: 5                        # batch size for training

  # Unet architecture parameters
  unet_hyperparameters:
    depth: 2                             # unet depth (=number of maxpooling layers)
    initial_features: 8                  # number of initial convolutions
    epochs: 50                         # training epochs
    train_split: 0.8                           # proportion of training (vs. validation) set, always between 0 and 1
    batch_norm: False                     # boolean value
    encoder_dropout: 0                   # dropout for encoder path
    decoder_dropout: 0                   # dropout for decoder path

prediction:
  active: false
  processing_tomo: "tomo"         # Column name in dataset table corresp. to tomogram that will be segmented
  semantic_class: 'ribo'          # Semantic class to be predicted

# Thresholding clustering and motl generation
postprocessing_clustering:
  active: false
  threshold: 0.001                       # Threshold for the probability score to make the predicted segmentation
  min_cluster_size: 100                  # Minimum number of voxels per cluster
  max_cluster_size: 35000                # Maximum number of voxels per cluster
  calculate_motl: False                  # Get the motl of centroids for each cluster
  ignore_border_thickness: 10            # ignore border for motl generation if calculate_motl is True
  region_mask: 'lamella_file'         # column name in metadata table for masking segmentation, e.g. lamella_file

# For precision recall in particle picking
evaluation:
  particle_picking:
    active: false
    pr_tolerance_radius: 10              # radius in voxels for considering two coordinate corresp. to same particle
    statistics_file: "pr_statistics.csv" # statistics file where area under pr curve will be stored
  segmentation_evaluation:
    active: false
    statistics_file: "dice_eval.csv"     # statistics file where the dice coefficient will be stored

debug: True
